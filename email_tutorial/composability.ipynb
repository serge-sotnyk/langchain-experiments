{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Composability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5041e79daabfe0f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Composability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e0c706c029573d7"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:09.184121500Z",
     "start_time": "2024-01-27T14:40:08.091282200Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:09.993387100Z",
     "start_time": "2024-01-27T14:40:09.184121500Z"
    }
   },
   "id": "dfd3583b0f13ed30",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:10.000898900Z",
     "start_time": "2024-01-27T14:40:09.994388900Z"
    }
   },
   "id": "bc0c54f2ee04e361",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"Why don't bears wear shoes?\\n\\nBecause they have bear feet!\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:11.380614700Z",
     "start_time": "2024-01-27T14:40:10.000898900Z"
    }
   },
   "id": "d8f0fb8b361d260f",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "set_verbose(False)\n",
    "set_debug(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:11.391113900Z",
     "start_time": "2024-01-27T14:40:11.386103100Z"
    }
   },
   "id": "dfff328fc2fb9849",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"bears\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"topic\": \"bears\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Tell me a joke about bears\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Tell me a joke about bears\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [1.04s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Sure, here's a bear-themed joke for you:\\n\\nWhy did the bear bring a ladder to the party?\\n\\nBecause it heard the drinks were on the house!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Sure, here's a bear-themed joke for you:\\n\\nWhy did the bear bring a ladder to the party?\\n\\nBecause it heard the drinks were on the house!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 32,\n",
      "      \"prompt_tokens\": 13,\n",
      "      \"total_tokens\": 45\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Sure, here's a bear-themed joke for you:\\n\\nWhy did the bear bring a ladder to the party?\\n\\nBecause it heard the drinks were on the house!\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence] [1.05s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Sure, here's a bear-themed joke for you:\\n\\nWhy did the bear bring a ladder to the party?\\n\\nBecause it heard the drinks were on the house!\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Sure, here's a bear-themed joke for you:\\n\\nWhy did the bear bring a ladder to the party?\\n\\nBecause it heard the drinks were on the house!\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:12.474867600Z",
     "start_time": "2024-01-27T14:40:11.395114300Z"
    }
   },
   "id": "d79a3fe91fb31315",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Batching"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c2cc140952522d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[\"Why don't bears wear shoes? \\n\\nBecause they already have bear feet!\",\n \"Why don't skeletons ever become clowns?\\n\\nBecause they don't have the guts for it!\"]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_debug(False)\n",
    "chain.batch([{\"topic\": \"bear\"}, {\"topic\": \"clowns\"}])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:13.375296700Z",
     "start_time": "2024-01-27T14:40:12.471871600Z"
    }
   },
   "id": "85c5c85925d3c367",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57c687347c30c5f3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " don\n",
      "'t\n",
      " bears\n",
      " wear\n",
      " shoes\n",
      "?\n",
      "\n",
      "\n",
      "Because\n",
      " they\n",
      " have\n",
      " bear\n",
      " feet\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:14.197207400Z",
     "start_time": "2024-01-27T14:40:13.370299700Z"
    }
   },
   "id": "a62b2c2d02bc9a78",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RunnablePassthrough"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d62c586849c7f2b7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.tavily_search_api import TavilySearchAPIRetriever\n",
    "\n",
    "retriever= TavilySearchAPIRetriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the context provided:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:14.403121100Z",
     "start_time": "2024-01-27T14:40:14.193209400Z"
    }
   },
   "id": "e6fa78063f868396",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:14.410918600Z",
     "start_time": "2024-01-27T14:40:14.407159700Z"
    }
   },
   "id": "9ddb2fb1836b70d2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Langsmith is a testing and observability platform developed by the Langchain team.'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is langsmith\"\n",
    "context = \"langsmith is a testing and observability platform built by the langchain team\"\n",
    "chain.invoke({\"question\": question, \"context\": context})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:15.136002200Z",
     "start_time": "2024-01-27T14:40:14.412919600Z"
    }
   },
   "id": "ac4b12b6d87001b7",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=(lambda x: x[\"question\"]) | retriever\n",
    ") | chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:15.137002600Z",
     "start_time": "2024-01-27T14:40:15.134003100Z"
    }
   },
   "id": "c35833dcf88d907e",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents. It allows users to debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs.'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke({\"question\": \"what is langsmith\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:18.710087500Z",
     "start_time": "2024-01-27T14:40:15.140004900Z"
    }
   },
   "id": "2fafd6f05c9571fa",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RunnableParallel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20fbb0b891cb44f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:40:53.341550100Z",
     "start_time": "2024-01-27T14:40:53.325078700Z"
    }
   },
   "id": "eae8fd5099c602fd",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"{question}\"\"\")\n",
    "simple_chain = prompt | model | output_parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:41:04.113119800Z",
     "start_time": "2024-01-27T14:41:04.089121400Z"
    }
   },
   "id": "2f19554a8d096dbb",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    \"retrieved_answer\": retrieval_chain,\n",
    "    \"simple_answer\": simple_chain\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:41:14.512000400Z",
     "start_time": "2024-01-27T14:41:14.435719200Z"
    }
   },
   "id": "2fb060a50bcb649c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'retrieved_answer': 'LangSmith is a platform that helps trace and evaluate language model applications and intelligent agents, allowing users to move from prototype to production. It provides features such as assessing subjective qualities that automatic evaluators struggle with, sampling and validating runs, and filtering and analyzing annotations. LangSmith also simplifies the setup process and allows users to edit examples, add them to datasets, and fine-tune models.',\n 'simple_answer': 'I\\'m sorry, but I couldn\\'t find any information on \"langsmith.\" It is possible that you may be referring to a specific term or concept that is not widely known or recognized. Could you please provide more context or clarify your question?'}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_chain.invoke({\"question\": \"what is langsmith\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:42:01.068659300Z",
     "start_time": "2024-01-27T14:41:57.268860500Z"
    }
   },
   "id": "442bba391b1a566c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'simple_answer': ''}\n",
      "{'simple_answer': 'Lang'}\n",
      "{'simple_answer': 'smith'}\n",
      "{'simple_answer': ' is'}\n",
      "{'simple_answer': ' not'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' widely'}\n",
      "{'simple_answer': ' known'}\n",
      "{'simple_answer': ' term'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' concept'}\n",
      "{'simple_answer': '.'}\n",
      "{'simple_answer': ' It'}\n",
      "{'simple_answer': ' does'}\n",
      "{'simple_answer': ' not'}\n",
      "{'simple_answer': ' have'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' specific'}\n",
      "{'simple_answer': ' definition'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' meaning'}\n",
      "{'simple_answer': ' in'}\n",
      "{'simple_answer': ' common'}\n",
      "{'simple_answer': ' usage'}\n",
      "{'simple_answer': '.'}\n",
      "{'simple_answer': ' It'}\n",
      "{'simple_answer': ' is'}\n",
      "{'simple_answer': ' possible'}\n",
      "{'simple_answer': ' that'}\n",
      "{'simple_answer': ' \"'}\n",
      "{'simple_answer': 'Lang'}\n",
      "{'simple_answer': 'smith'}\n",
      "{'simple_answer': '\"'}\n",
      "{'simple_answer': ' could'}\n",
      "{'simple_answer': ' be'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' surname'}\n",
      "{'simple_answer': ' or'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' company'}\n",
      "{'simple_answer': ' name'}\n",
      "{'simple_answer': ','}\n",
      "{'simple_answer': ' but'}\n",
      "{'simple_answer': ' without'}\n",
      "{'simple_answer': ' more'}\n",
      "{'simple_answer': ' context'}\n",
      "{'simple_answer': ','}\n",
      "{'simple_answer': ' it'}\n",
      "{'simple_answer': ' is'}\n",
      "{'simple_answer': ' difficult'}\n",
      "{'simple_answer': ' to'}\n",
      "{'simple_answer': ' provide'}\n",
      "{'simple_answer': ' a'}\n",
      "{'simple_answer': ' specific'}\n",
      "{'simple_answer': ' answer'}\n",
      "{'simple_answer': '.'}\n",
      "{'simple_answer': ''}\n",
      "{'retrieved_answer': ''}\n",
      "{'retrieved_answer': 'Lang'}\n",
      "{'retrieved_answer': 'Smith'}\n",
      "{'retrieved_answer': ' is'}\n",
      "{'retrieved_answer': ' a'}\n",
      "{'retrieved_answer': ' platform'}\n",
      "{'retrieved_answer': ' that'}\n",
      "{'retrieved_answer': ' helps'}\n",
      "{'retrieved_answer': ' trace'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' evaluate'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' debug'}\n",
      "{'retrieved_answer': ' language'}\n",
      "{'retrieved_answer': ' model'}\n",
      "{'retrieved_answer': ' applications'}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' intelligent'}\n",
      "{'retrieved_answer': ' agents'}\n",
      "{'retrieved_answer': '.'}\n",
      "{'retrieved_answer': ' It'}\n",
      "{'retrieved_answer': ' provides'}\n",
      "{'retrieved_answer': ' features'}\n",
      "{'retrieved_answer': ' such'}\n",
      "{'retrieved_answer': ' as'}\n",
      "{'retrieved_answer': ' tracking'}\n",
      "{'retrieved_answer': ' system'}\n",
      "{'retrieved_answer': '-level'}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' model'}\n",
      "{'retrieved_answer': '/'}\n",
      "{'retrieved_answer': 'chain'}\n",
      "{'retrieved_answer': ' performance'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' debugging'}\n",
      "{'retrieved_answer': ' issues'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' creating'}\n",
      "{'retrieved_answer': ' datasets'}\n",
      "{'retrieved_answer': ' from'}\n",
      "{'retrieved_answer': ' logs'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' testing'}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' benchmark'}\n",
      "{'retrieved_answer': 'ing'}\n",
      "{'retrieved_answer': ' L'}\n",
      "{'retrieved_answer': 'LM'}\n",
      "{'retrieved_answer': ' systems'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' monitoring'}\n",
      "{'retrieved_answer': ' and'}\n",
      "{'retrieved_answer': ' personal'}\n",
      "{'retrieved_answer': 'izing'}\n",
      "{'retrieved_answer': ' applications'}\n",
      "{'retrieved_answer': '.'}\n",
      "{'retrieved_answer': ' Lang'}\n",
      "{'retrieved_answer': 'Smith'}\n",
      "{'retrieved_answer': ' also'}\n",
      "{'retrieved_answer': ' offers'}\n",
      "{'retrieved_answer': ' a'}\n",
      "{'retrieved_answer': ' unified'}\n",
      "{'retrieved_answer': ' hub'}\n",
      "{'retrieved_answer': ' for'}\n",
      "{'retrieved_answer': ' these'}\n",
      "{'retrieved_answer': ' functionalities'}\n",
      "{'retrieved_answer': ','}\n",
      "{'retrieved_answer': ' making'}\n",
      "{'retrieved_answer': ' it'}\n",
      "{'retrieved_answer': ' easier'}\n",
      "{'retrieved_answer': ' for'}\n",
      "{'retrieved_answer': ' developers'}\n",
      "{'retrieved_answer': ' to'}\n",
      "{'retrieved_answer': ' work'}\n",
      "{'retrieved_answer': ' with'}\n",
      "{'retrieved_answer': ' L'}\n",
      "{'retrieved_answer': 'LM'}\n",
      "{'retrieved_answer': 's'}\n",
      "{'retrieved_answer': '.'}\n",
      "{'retrieved_answer': ''}\n"
     ]
    }
   ],
   "source": [
    "for s in parallel_chain.stream({\"question\": \"what is langsmith\"}):\n",
    "    print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T14:42:26.556870800Z",
     "start_time": "2024-01-27T14:42:22.740083100Z"
    }
   },
   "id": "bfa5ec1dab7a1f1d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "655b6f366c9d98d4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
