{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Streaming\n",
    "\n",
    "This notebook covers functionality related to streaming.\n",
    "\n",
    "For more information, see:\n",
    "\n",
    "* [Streaming with LCEL](https://python.langchain.com/docs/expression_language/interface#stream)\n",
    "* [Streaming for RAG](https://python.langchain.com/docs/use_cases/question_answering/streaming)\n",
    "* [Streaming for Agents](https://python.langchain.com/docs/modules/agents/how_to/streaming)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b5e47e4463d71e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Streaming"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d298d7111fe338d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:17:06.793274600Z",
     "start_time": "2024-01-29T09:17:01.418102300Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:17:10.354627700Z",
     "start_time": "2024-01-29T09:17:09.164008Z"
    }
   },
   "id": "75f3aea5c7982ca8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's a bear joke for you:\n",
      "\n",
      "Why do bears never get asked to play cards?\n",
      "\n",
      "Because they're always caught \"bear-handed\"!"
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:17:42.665370200Z",
     "start_time": "2024-01-29T09:17:40.407388100Z"
    }
   },
   "id": "10bcad355922566e",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Streaming with RunnableParallel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29ed734b8e41265e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poem': ''}\n",
      "{'poem': 'In'}\n",
      "{'poem': ' forests'}\n",
      "{'poem': ' deep'}\n",
      "{'poem': ','}\n",
      "{'poem': ' where'}\n",
      "{'poem': ' shadows'}\n",
      "{'joke': ''}\n",
      "{'poem': ' dwell'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'Beh'}\n",
      "{'poem': 'old'}\n",
      "{'poem': ' the'}\n",
      "{'poem': ' creatures'}\n",
      "{'joke': 'Sure'}\n",
      "{'joke': ','}\n",
      "{'joke': ' here'}\n",
      "{'poem': ','}\n",
      "{'poem': ' fierce'}\n",
      "{'poem': ' and'}\n",
      "{'joke': \"'s\"}\n",
      "{'joke': ' a'}\n",
      "{'poem': ' fell'}\n",
      "{'joke': ' bear'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'With'}\n",
      "{'joke': ' joke'}\n",
      "{'joke': ' for'}\n",
      "{'joke': ' you'}\n",
      "{'joke': ':\\n\\n'}\n",
      "{'joke': 'Why'}\n",
      "{'joke': ' don'}\n",
      "{'joke': \"'t\"}\n",
      "{'joke': ' bears'}\n",
      "{'joke': ' wear'}\n",
      "{'poem': ' strength'}\n",
      "{'poem': ' unmatched'}\n",
      "{'poem': ','}\n",
      "{'poem': ' and'}\n",
      "{'poem': ' claws'}\n",
      "{'joke': ' shoes'}\n",
      "{'joke': '?\\n\\n'}\n",
      "{'joke': 'Because'}\n",
      "{'poem': ' so'}\n",
      "{'poem': ' sharp'}\n",
      "{'poem': ',\\n'}\n",
      "{'joke': ' they'}\n",
      "{'joke': ' have'}\n",
      "{'joke': ' bear'}\n",
      "{'joke': ' feet'}\n",
      "{'joke': '!'}\n",
      "{'joke': ''}\n",
      "{'poem': 'The'}\n",
      "{'poem': ' mighty'}\n",
      "{'poem': ' bears'}\n",
      "{'poem': ','}\n",
      "{'poem': ' the'}\n",
      "{'poem': ' rulers'}\n",
      "{'poem': ' of'}\n",
      "{'poem': ' the'}\n",
      "{'poem': ' dark'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'Their'}\n",
      "{'poem': ' fur'}\n",
      "{'poem': ','}\n",
      "{'poem': ' a'}\n",
      "{'poem': ' cloak'}\n",
      "{'poem': ' of'}\n",
      "{'poem': ' deepest'}\n",
      "{'poem': ' brown'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'A'}\n",
      "{'poem': ' symbol'}\n",
      "{'poem': ' of'}\n",
      "{'poem': ' the'}\n",
      "{'poem': ' wild'}\n",
      "{'poem': \"'s\"}\n",
      "{'poem': ' renown'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'With'}\n",
      "{'poem': ' eyes'}\n",
      "{'poem': ' that'}\n",
      "{'poem': ' gle'}\n",
      "{'poem': 'am'}\n",
      "{'poem': ' like'}\n",
      "{'poem': ' amber'}\n",
      "{'poem': ' fire'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'They'}\n",
      "{'poem': ' roam'}\n",
      "{'poem': ' the'}\n",
      "{'poem': ' land'}\n",
      "{'poem': ','}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' hearts'}\n",
      "{'poem': ' aspire'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'From'}\n",
      "{'poem': ' towering'}\n",
      "{'poem': ' p'}\n",
      "{'poem': 'ines'}\n",
      "{'poem': ' to'}\n",
      "{'poem': ' icy'}\n",
      "{'poem': ' streams'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'They'}\n",
      "{'poem': ' wander'}\n",
      "{'poem': ' through'}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' ancient'}\n",
      "{'poem': ' dreams'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'In'}\n",
      "{'poem': ' solitude'}\n",
      "{'poem': ','}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' find'}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' might'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'A'}\n",
      "{'poem': ' symbol'}\n",
      "{'poem': ' of'}\n",
      "{'poem': ' nature'}\n",
      "{'poem': \"'s\"}\n",
      "{'poem': ' endless'}\n",
      "{'poem': ' fight'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'Through'}\n",
      "{'poem': ' seasons'}\n",
      "{'poem': ' changing'}\n",
      "{'poem': ','}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' endure'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'Their'}\n",
      "{'poem': ' spirits'}\n",
      "{'poem': ' strong'}\n",
      "{'poem': ','}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' hearts'}\n",
      "{'poem': ' pure'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'From'}\n",
      "{'poem': ' h'}\n",
      "{'poem': 'ibern'}\n",
      "{'poem': 'ation'}\n",
      "{'poem': \"'s\"}\n",
      "{'poem': ' peaceful'}\n",
      "{'poem': ' rest'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'They'}\n",
      "{'poem': ' rise'}\n",
      "{'poem': ','}\n",
      "{'poem': ' embracing'}\n",
      "{'poem': ' each'}\n",
      "{'poem': ' new'}\n",
      "{'poem': ' quest'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'With'}\n",
      "{'poem': ' gentle'}\n",
      "{'poem': ' grace'}\n",
      "{'poem': ','}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' tend'}\n",
      "{'poem': ' to'}\n",
      "{'poem': ' young'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'Their'}\n",
      "{'poem': ' love'}\n",
      "{'poem': ','}\n",
      "{'poem': ' a'}\n",
      "{'poem': ' song'}\n",
      "{'poem': ' that'}\n",
      "{'poem': \"'s\"}\n",
      "{'poem': ' never'}\n",
      "{'poem': ' sung'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'In'}\n",
      "{'poem': ' forests'}\n",
      "{'poem': ' wide'}\n",
      "{'poem': ','}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' teach'}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' kin'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'A'}\n",
      "{'poem': ' legacy'}\n",
      "{'poem': ' that'}\n",
      "{'poem': ' time'}\n",
      "{'poem': ' won'}\n",
      "{'poem': \"'t\"}\n",
      "{'poem': ' dim'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'But'}\n",
      "{'poem': ' do'}\n",
      "{'poem': ' not'}\n",
      "{'poem': ' underestimate'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'The'}\n",
      "{'poem': ' power'}\n",
      "{'poem': ' that'}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' hold'}\n",
      "{'poem': ' innate'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'For'}\n",
      "{'poem': ' when'}\n",
      "{'poem': ' provoked'}\n",
      "{'poem': ','}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' fiercely'}\n",
      "{'poem': ' fight'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'Protect'}\n",
      "{'poem': 'ing'}\n",
      "{'poem': ' all'}\n",
      "{'poem': ' with'}\n",
      "{'poem': ' all'}\n",
      "{'poem': ' their'}\n",
      "{'poem': ' might'}\n",
      "{'poem': '.\\n\\n'}\n",
      "{'poem': 'So'}\n",
      "{'poem': ' let'}\n",
      "{'poem': ' us'}\n",
      "{'poem': ' honor'}\n",
      "{'poem': ' bears'}\n",
      "{'poem': ','}\n",
      "{'poem': ' we'}\n",
      "{'poem': ' praise'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'Through'}\n",
      "{'poem': ' words'}\n",
      "{'poem': ' and'}\n",
      "{'poem': ' art'}\n",
      "{'poem': ','}\n",
      "{'poem': ' in'}\n",
      "{'poem': ' countless'}\n",
      "{'poem': ' ways'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'For'}\n",
      "{'poem': ' they'}\n",
      "{'poem': ' symbol'}\n",
      "{'poem': 'ize'}\n",
      "{'poem': ' strength'}\n",
      "{'poem': ' and'}\n",
      "{'poem': ' might'}\n",
      "{'poem': ',\\n'}\n",
      "{'poem': 'A'}\n",
      "{'poem': ' symbol'}\n",
      "{'poem': ' of'}\n",
      "{'poem': ' nature'}\n",
      "{'poem': \"'s\"}\n",
      "{'poem': ' endless'}\n",
      "{'poem': ' light'}\n",
      "{'poem': '.'}\n",
      "{'poem': ''}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "chain1 = prompt | model | output_parser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Write me a poem about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | model | output_parser\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\": chain1,\n",
    "    \"poem\": chain2\n",
    "})\n",
    "\n",
    "for s in parallel_chain.stream({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:20:20.835253600Z",
     "start_time": "2024-01-29T09:20:12.344458700Z"
    }
   },
   "id": "b4455a6eb9b43492",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke\n",
      "poem\n"
     ]
    }
   ],
   "source": [
    "for s in parallel_chain.invoke({\"topic\": \"bears\"}):\n",
    "    print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:21:48.634689500Z",
     "start_time": "2024-01-29T09:21:43.071089400Z"
    }
   },
   "id": "8a930e15d4e26188",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\"'poem'\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:22:18.134367700Z",
     "start_time": "2024-01-29T09:22:17.674012Z"
    }
   },
   "id": "65fccedcd47d751c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stream Log"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "202855089732d59f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_community.retrievers.tavily_search_api import TavilySearchAPIRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retriever= TavilySearchAPIRetriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the question based only on the context provided:\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "retrieval_chain = RunnablePassthrough.assign(\n",
    "    context=(lambda x: x[\"question\"]) | retriever.with_config(run_name=\"Docs\")\n",
    ") | chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:33:29.347637100Z",
     "start_time": "2024-01-29T09:33:28.551792800Z"
    }
   },
   "id": "428411b3d5995004",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It provides tools to trace and evaluate language model applications and intelligent agents, as well as to track system-level and model/chain performance. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs."
     ]
    }
   ],
   "source": [
    "for s in retrieval_chain.stream({\"question\": \"what is langsmith\"}):\n",
    "    print(s, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:33:47.139241600Z",
     "start_time": "2024-01-29T09:33:42.288832700Z"
    }
   },
   "id": "5c471f7d56a10b80",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '21100807-4323-43e2-9e62-28220533198b',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<context>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '19efbacc-1f3d-41f3-a2be-3af8fc55a469',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableAssign<context>',\n",
      "            'start_time': '2024-01-29T09:34:46.078+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<context>/streamed_output/-',\n",
      "  'value': {'question': 'what is langsmith'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<context>',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '925ba3eb-8a8f-4a02-9fcd-66fb6360f6c6',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableParallel<context>',\n",
      "            'start_time': '2024-01-29T09:34:46.079+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': [],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '9720468f-9ff5-4eba-a721-f5e35b231330',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'start_time': '2024-01-29T09:34:46.081+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['map:key:context'],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '424e1a48-29e0-4237-82b3-cc47c8f17d0d',\n",
      "            'metadata': {},\n",
      "            'name': 'RunnableLambda',\n",
      "            'start_time': '2024-01-29T09:34:46.083+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:1'],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/streamed_output/-',\n",
      "  'value': 'what is langsmith'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/final_output',\n",
      "  'value': {'output': 'what is langsmith'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableLambda/end_time',\n",
      "  'value': '2024-01-29T09:34:46.085+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '6a1c410a-8514-470f-a894-6ddf547eef4f',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2024-01-29T09:34:46.522+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2'],\n",
      "            'type': 'retriever'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                          Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                          Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                          Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                          Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                          Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                          Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                          Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                          Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                          Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2024-01-29T09:34:48.068+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence/streamed_output/-',\n",
      "  'value': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "            Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "            Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "            Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "            Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "            Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "            Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "            Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "            Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "            Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<context>/streamed_output/-',\n",
      "  'value': {'context': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                        Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                        Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                        Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                        Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                        Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                        Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                        Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                        Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                        Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<context>/streamed_output/-',\n",
      "  'value': {'context': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                        Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                        Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                        Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                        Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                        Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                        Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                        Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                        Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                        Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableSequence/final_output',\n",
      "  'value': {'output': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                       Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                       Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                       Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                       Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                       Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                       Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                       Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                       Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                       Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableSequence/end_time',\n",
      "  'value': '2024-01-29T09:34:48.075+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<context>/final_output',\n",
      "  'value': {'context': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                        Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                        Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                        Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                        Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                        Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                        Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                        Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                        Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                        Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableParallel<context>/end_time',\n",
      "  'value': '2024-01-29T09:34:48.076+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<context>/final_output',\n",
      "  'value': {'context': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.9761, 'images': None}),\n",
      "                        Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.94574, 'images': None}),\n",
      "                        Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.9352, 'images': None}),\n",
      "                        Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.92435, 'images': None}),\n",
      "                        Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90168, 'images': None}),\n",
      "                        Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", metadata={'title': 'LangSmith: Best Way to Test LLMs and AI Application', 'source': 'https://cheatsheet.md/langchain-tutorials/langsmith.en', 'score': 0.89895, 'images': None}),\n",
      "                        Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.88421, 'images': None}),\n",
      "                        Document(page_content='The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\nBefore we discuss the results, take a look at the LangSmith hub:\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\nFigure 9.', metadata={'title': 'What is LangSmith? Tracing and debugging for LLMs | InfoWorld', 'source': 'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html', 'score': 0.86584, 'images': None}),\n",
      "                        Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.8609, 'images': None}),\n",
      "                        Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.82534, 'images': None})],\n",
      "            'question': 'what is langsmith'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/RunnableAssign<context>/end_time',\n",
      "  'value': '2024-01-29T09:34:48.078+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '94ffcc41-c154-47a7-958a-f768f53fea03',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatPromptTemplate',\n",
      "            'start_time': '2024-01-29T09:34:48.080+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2'],\n",
      "            'type': 'prompt'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate/final_output',\n",
      "  'value': ChatPromptValue(messages=[HumanMessage(content='Answer the question based only on the context provided:\\n\\nContext: [Document(page_content=\\'LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.\\', metadata={\\'title\\': \\'LangSmith | ️ Langchain\\', \\'source\\': \\'https://python.langchain.com/docs/langsmith/\\', \\'score\\': 0.9761, \\'images\\': None}), Document(page_content=\\'This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\\\n You can accomplish this by following the shell commands provided below:\\\\nCreating a LangSmith client\\\\nNext, create a LangSmith client to interact with the API:\\\\nIf you’re using Python, run the following commands to import the module:\\\\n This code also handles exceptions that may occur during the agent execution:\\\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\\\nInput processing with exception handling\\\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.\\', metadata={\\'title\\': \\'Using LangSmith to test LLMs and AI applications\\', \\'source\\': \\'https://blog.logrocket.com/langsmith-test-llms-ai-applications/\\', \\'score\\': 0.94574, \\'images\\': None}), Document(page_content=\\'We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\\\nDebugging\\\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\\\n A unified platform\\\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\\\n\\', metadata={\\'title\\': \\'Announcing LangSmith, a unified platform for debugging, testing ...\\', \\'source\\': \\'https://blog.langchain.dev/announcing-langsmith/\\', \\'score\\': 0.9352, \\'images\\': None}), Document(page_content=\"BETA Sign Up\\\\nContact Sales\\\\nProducts and use-cases\\\\nLangChain\\\\nLangSmith\\\\nRetrieval\\\\nAgents\\\\nInspiration\\\\nCode\\\\nGitHub\\\\nLangChain Hub\\\\nPython Docs\\\\nJS/TS Docs\\\\nSocial\\\\nTwitter\\\\nDiscord\\\\nBlog\\\\nLinkedIn\\\\nYouTube\\\\nTerms of Service\\\\nSign up for our newsletter\\\\nProducts and use-cases\\\\nLangChain\\\\nLangSmith\\\\nRetrieval\\\\nAgents\\\\nInspiration\\\\nCode\\\\nGitHub\\\\nLangChain Hub\\\\nPython Docs\\\\nJS/TS Docs\\\\nSocial\\\\nTwitter\\\\nDiscord\\\\nBlog\\\\nLinkedIn\\\\nYouTube\\\\nTerms of Service\\\\nSign up for our newsletter\\\\nProducts and use-cases\\\\nLangChain\\\\nLangSmith\\\\nRetrieval\\\\nAgents\\\\nInspiration\\\\nCode\\\\nGitHub\\\\nLangChain Hub\\\\nPython Docs\\\\nJS/TS Docs\\\\nSocial\\\\nTwitter\\\\nDiscord\\\\nBlog\\\\nLinkedIn\\\\nYouTube\\\\nTerms of Service\\\\nSign up for our newsletter 🦜🔗 LangChain\\\\nLangSmith\\\\nLangServe\\\\nAgents\\\\nRetrieval\\\\nEvaluation\\\\nBlog\\\\nDocs\\\\n🦜🔗 LangChain\\\\nBuild and deploy LLM apps with confidence\\\\nAn all-in-one developer platform for every step of the application lifecycle.\\\\n Prompt playground\\\\nCross-team collaboration\\\\nCatalog of ranging models & tasks\\\\nProven prompting strategies\\\\nExplore LangChain Hub\\\\nTurn the magic of LLM applications into enterprise-ready products\\\\nNative collaboration\\\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\\\n Application-level usage stats\\\\nFeedback collection\\\\nFilter traces\\\\nCost measurement\\\\nPerformance comparison\\\\nGo To Docs\\\\nManage Prompts\\\\nPrompts power your team\\'s chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\\\nEvaluate chain performance\\\\nAI-assisted evaluation\\\\nEasy benchmarking\\\\nGo To Docs\\\\nMonitor\\\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={\\'title\\': \\'LangSmith\\', \\'source\\': \\'https://www.langchain.com/langsmith\\', \\'score\\': 0.92435, \\'images\\': None}), Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\\\nIf you don\\'t want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\\\n Quick Start\\\\u200b\\\\nIf following along with code is more your thing, we\\'ve set up a Jupyter notebook at this link to help you get started with LangSmith.\\\\n LangChain JS Docs for the TypeScript LangChain library\\\\nDiscord: Join us on our Discord to discuss all things LangChain!\\\\n Next Steps\\\\u200b\\\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\\\n\", metadata={\\'title\\': \\'LangSmith | ️ ️ LangSmith\\', \\'source\\': \\'https://docs.smith.langchain.com/\\', \\'score\\': 0.90168, \\'images\\': None}), Document(page_content=\"LangSmith Cookbook: Real-world Lang Smith Examples\\\\nThe LangSmith Cookbook is not just a compilation of code snippets; it\\'s a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\\\nLangSmith: Best Way to Test LLMs and AI Application\\\\nPublished on 12/17/2023\\\\nIf you\\'re in the world of Language Learning Models (LLMs), you\\'ve probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\\\n How do I get access to LangSmith?\\\\nTo get access to LangSmith, you\\'ll need to sign up for an account on their website.\", metadata={\\'title\\': \\'LangSmith: Best Way to Test LLMs and AI Application\\', \\'source\\': \\'https://cheatsheet.md/langchain-tutorials/langsmith.en\\', \\'score\\': 0.89895, \\'images\\': None}), Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\\\nAdvice for Product Teams Considering LangSmith\\\\nWhen you\\'re in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\\\n\", metadata={\\'title\\': \\'Peering Into the Soul of AI Decision-Making with LangSmith\\', \\'source\\': \\'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/\\', \\'score\\': 0.88421, \\'images\\': None}), Document(page_content=\\'The Run tab for the top-level chain shows the human input, the parsed output, the latency (under a second), and the tokens used, as well as the clock time and call status.\\\\n The cookbook covers tracing your code without LangChain (using the @traceable decorator); using the LangChain Hub to discover, share, and version control prompts; testing and benchmarking your LLM systems in Python and TypeScript or JavaScript; using user feedback to improve, monitor, and personalize your applications; exporting data for fine-tuning; and exporting your run data for exploratory data analysis.\\\\n In addition to the input variables (prompt), an LLM call uses a template and often auxiliary functions; for example, retrieval of information from the web, uploaded files, and system prompts that set the context for the LLM.\\\\n After I set up my LangSmith account, created my API key, updated my LangChain installation with pip, and set up my shell environment variables, I tried to run the Python quickstart application:\\\\nBefore we discuss the results, take a look at the LangSmith hub:\\\\nFigure 1. Here are the evaluation statistics, which were printed in the terminal during the run:\\\\nSomebody had fun creating the rap battle prompts, as shown in the dataset below:\\\\nFigure 9.\\', metadata={\\'title\\': \\'What is LangSmith? Tracing and debugging for LLMs | InfoWorld\\', \\'source\\': \\'https://www.infoworld.com/article/3708628/what-is-langsmith-tracing-and-debugging-for-llms.html\\', \\'score\\': 0.86584, \\'images\\': None}), Document(page_content=\\'A deep dive into the latest product from the creators of LangChain 🦜\\\\n--\\\\n3\\\\nCobus Greyling\\\\nLangSmith\\\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\\\n--\\\\nLists\\\\nNatural Language Processing\\\\nPredictive Modeling w/ Python\\\\nAI Regulation\\\\nPractical Guides to Machine Learning\\\\nYule Wang, PhD\\\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\\\n—\\\\u200a—\\\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\\\n--\\\\n1\\\\nRyan Nguyen\\\\nin\\\\nBetter Programming\\\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\\\n--\\\\n2\\\\nKelvin Lu\\\\nTracing How LangChain Works Behind the Scenes\\\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\\\n --\\\\nCameron R. Wolfe, Ph.D.\\\\nin\\\\nTowards Data Science\\\\nChain of Thought Prompting for LLMs\\\\nA practical and simple approach for “reasoning” with LLMs\\\\n--\\\\nHelp\\\\nStatus\\\\nAbout\\\\nCareers\\\\nBlog\\\\nPrivacy\\\\nTerms\\\\nText to speech\\\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\\\n--\\\\nBenoit Ruiz\\\\nin\\\\nBetter Programming\\\\nAdvice From a Software Engineer With 8 Years of Experience\\\\nPractical tips for those who want to advance in their careers\\\\n--\\\\n233\\\\nVinita\\\\nin\\\\nBetter Programming\\\\n4 Strategies to Give Effective Feedback to a Difficult Person\\\\nRespect is like air. But if you take it away, it’s all that people can think about.\\\\n--\\\\n21\\\\nRicardo Ledan\\\\nin\\\\nBetter Programming\\\\nBuilding Context-Aware Question-Answering Systems With LLMs\\\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\\\n--\\\\n1\\\\nRecommended from Medium\\\\nLogan Kilpatrick\\\\nWhat is LangSmith and why should I care as a developer?\\\\n Ricardo Ledan\\\\nFollow\\\\nBetter Programming\\\\n--\\\\nShare\\\\nWhat is LangSmith?\\\\n\\', metadata={\\'title\\': \\'The Art of LangSmithing - Better Programming\\', \\'source\\': \\'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220\\', \\'score\\': 0.8609, \\'images\\': None}), Document(page_content=\\'But what are the production challenges that need to be solved which were not as relevant in prototyping?\\\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\\\n for tools\\\\nKim Seon Woo - Nov 6\\\\nComo deixar o Swagger com tema dark mode usando NestJS\\\\nWiliam V. Joaquim - Nov 5\\\\nData visualizing\\\\nBIRINGANINE BASEME Destin\\\\n- Oct 7\\\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\\\nWhat is LangSmith?\\', metadata={\\'title\\': \\'What is LangSmith and why should I care as a developer?\\', \\'source\\': \\'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k\\', \\'score\\': 0.82534, \\'images\\': None})]\\n\\nQuestion: what is langsmith')])},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatPromptTemplate/end_time',\n",
      "  'value': '2024-01-29T09:34:48.081+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '2b9c194f-2440-416e-9cc9-14ad3834ae6b',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'start_time': '2024-01-29T09:34:48.082+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:3'],\n",
      "            'type': 'llm'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '36c259f2-a794-417f-a6e5-9fc4dbf969c7',\n",
      "            'metadata': {},\n",
      "            'name': 'StrOutputParser',\n",
      "            'start_time': '2024-01-29T09:34:48.618+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:4'],\n",
      "            'type': 'parser'}})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ''})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': ''})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Lang'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Lang'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Lang')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'Smith'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Smith'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Smith'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Smith')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' is'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' is'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' is'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' is')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' a'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' a'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is a'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' platform'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' platform'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is a platform'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' platform'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' platform')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' that'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' that'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' that'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' that')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' offers'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' offers'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' offers'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' offers')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' features'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' features'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' features'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' features')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' for'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' for'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' for'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' for')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' debugging'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' debugging'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' debugging'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' debugging')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' testing'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' testing'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' testing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' testing')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' evaluating'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' evaluating'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' evaluating'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' evaluating')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' monitoring'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' monitoring'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' monitoring'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' monitoring')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' Language'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Language'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' Language'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Language')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' Learning'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Learning'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' Learning'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Learning')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' Models'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Models'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' Models'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Models')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' ('})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' ('},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models ('})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ' ('},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' (')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'LL'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'LL'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models (LL'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': 'LL'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='LL')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'Ms'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Ms'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': 'Ms'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Ms')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ')'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ')'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs)'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ')'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=')')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' AI'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' AI'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' AI'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' AI')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' applications'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' applications'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' applications'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' applications')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': '.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications.'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' It'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' It'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' It'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' It')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' helps'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' helps'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' helps'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' helps')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' track'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' track'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' track'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' track')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' system'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' system'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' system'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' system')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': '-level'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '-level'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': '-level'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-level')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' performance'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' performance'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' performance'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' performance')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' debug'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' debug'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' debug'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' debug')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' issues'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' issues'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' issues'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' issues')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' establish'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' establish'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' establish'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' establish')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' user'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' user'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' user'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' user')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' interactions'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' interactions'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' interactions'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' interactions')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' provides'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' provides'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' provides'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' provides')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' visibility'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' visibility'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' visibility'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' visibility')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' into'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' into'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' into'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' into')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' model'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' model'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' model'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' model')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' inputs'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' inputs'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' inputs'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' inputs')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' outputs'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' outputs'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' outputs'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' outputs')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': '.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs.'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' It'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' It'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' It'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' It')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' also'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' also'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' also'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' also')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' serves'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' serves'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' serves'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' serves')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' as'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' as'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' as'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' as')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' a'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' a'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ' a'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' a')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' unified'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' unified'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' unified'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' unified')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' platform'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' platform'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' platform'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' platform')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' for'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' for'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' for'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' for')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' managing'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' managing'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' managing'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' managing')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' refining'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' refining'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' refining'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' refining')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' prompts'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' prompts'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' prompts'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' prompts')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' evaluating'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' evaluating'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' evaluating'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' evaluating')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' chain'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' chain'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' chain'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' chain')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' performance'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' performance'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' performance'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' performance')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' collecting'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' collecting'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' collecting'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' collecting')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' feedback'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' feedback'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' feedback'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' feedback')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': '.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback.'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Lang'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. Lang'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'Smith'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Smith'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Smith'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Smith')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' seamlessly'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' seamlessly'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' seamlessly'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' seamlessly')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' integrates'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' integrates'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' integrates'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' integrates')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' with'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' with'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' with'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' with')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Lang'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with Lang'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' Lang'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Lang')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'Chain'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Chain'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': 'Chain'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='Chain')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ','})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain,'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' an'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' an'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' an'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' an')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' open'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' open'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' open'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' open')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': '-source'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '-source'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': '-source'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-source')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' framework'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' framework'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' framework'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' framework')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' for'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' for'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework '\n",
      "           'for'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' for'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' for')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' building'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' building'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' building'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' building')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' with'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' with'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building with'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output_str/-',\n",
      "  'value': ' with'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' with')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': ' L'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' L'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building with L'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ' L'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' L')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/streamed_output/-',\n",
      "  'value': 'LM'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'LM'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building with LLM'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': 'LM'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='LM')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': 's'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 's'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building with LLMs'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': 's'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='s')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': '.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that offers features for debugging, '\n",
      "           'testing, evaluating, and monitoring Language Learning Models '\n",
      "           '(LLMs) and AI applications. It helps track system-level '\n",
      "           'performance, debug issues, establish user interactions, and '\n",
      "           'provides visibility into model inputs and outputs. It also serves '\n",
      "           'as a unified platform for managing and refining prompts, '\n",
      "           'evaluating chain performance, and collecting feedback. LangSmith '\n",
      "           'seamlessly integrates with LangChain, an open-source framework for '\n",
      "           'building with LLMs.'})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})RunLogPatch({'op': 'add', 'path': '/logs/StrOutputParser/streamed_output/-', 'value': ''})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/final_output',\n",
      "  'value': {'generations': [[{'generation_info': {'finish_reason': 'stop'},\n",
      "                              'message': AIMessageChunk(content='LangSmith is a platform that offers features for debugging, testing, evaluating, and monitoring Language Learning Models (LLMs) and AI applications. It helps track system-level performance, debug issues, establish user interactions, and provides visibility into model inputs and outputs. It also serves as a unified platform for managing and refining prompts, evaluating chain performance, and collecting feedback. LangSmith seamlessly integrates with LangChain, an open-source framework for building with LLMs.'),\n",
      "                              'text': 'LangSmith is a platform that offers '\n",
      "                                      'features for debugging, testing, '\n",
      "                                      'evaluating, and monitoring Language '\n",
      "                                      'Learning Models (LLMs) and AI '\n",
      "                                      'applications. It helps track '\n",
      "                                      'system-level performance, debug issues, '\n",
      "                                      'establish user interactions, and '\n",
      "                                      'provides visibility into model inputs '\n",
      "                                      'and outputs. It also serves as a '\n",
      "                                      'unified platform for managing and '\n",
      "                                      'refining prompts, evaluating chain '\n",
      "                                      'performance, and collecting feedback. '\n",
      "                                      'LangSmith seamlessly integrates with '\n",
      "                                      'LangChain, an open-source framework for '\n",
      "                                      'building with LLMs.',\n",
      "                              'type': 'ChatGenerationChunk'}]],\n",
      "            'llm_output': None,\n",
      "            'run': None}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/end_time',\n",
      "  'value': '2024-01-29T09:34:50.832+00:00'})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/final_output',\n",
      "  'value': {'output': 'LangSmith is a platform that offers features for '\n",
      "                      'debugging, testing, evaluating, and monitoring Language '\n",
      "                      'Learning Models (LLMs) and AI applications. It helps '\n",
      "                      'track system-level performance, debug issues, establish '\n",
      "                      'user interactions, and provides visibility into model '\n",
      "                      'inputs and outputs. It also serves as a unified '\n",
      "                      'platform for managing and refining prompts, evaluating '\n",
      "                      'chain performance, and collecting feedback. LangSmith '\n",
      "                      'seamlessly integrates with LangChain, an open-source '\n",
      "                      'framework for building with LLMs.'}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/StrOutputParser/end_time',\n",
      "  'value': '2024-01-29T09:34:50.836+00:00'})"
     ]
    }
   ],
   "source": [
    "async for s in retrieval_chain.astream_log({\"question\": \"what is langsmith\"}):\n",
    "    print(s, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:34:50.850631500Z",
     "start_time": "2024-01-29T09:34:45.933232900Z"
    }
   },
   "id": "6afe1ad3d4f8477f",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '37be2b95-3f5e-40e4-bf46-7db54659028e',\n",
      "            'logs': {},\n",
      "            'name': 'RunnableSequence',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '1bfa4c12-c2b7-4f55-9a5c-676f23699bcc',\n",
      "            'metadata': {},\n",
      "            'name': 'Docs',\n",
      "            'start_time': '2024-01-29T09:36:37.861+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:2'],\n",
      "            'type': 'retriever'}})RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/Docs/final_output',\n",
      "  'value': {'documents': [Document(page_content='LangSmith | 🦜️🔗 Langchain LangSmith LangSmith LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you move from prototype to production. Check out the interactive walkthrough to get started. For more information, please refer to the LangSmith documentation.', metadata={'title': 'LangSmith | ️ Langchain', 'source': 'https://python.langchain.com/docs/langsmith/', 'score': 0.96979, 'images': None}),\n",
      "                          Document(page_content='This function helps to load the specific language models and tools required for the task as shown in the code snippet below:\\nAs a next step, initialize an agent by calling the initialize_agent function with several parameters like tools, llms, and agent:\\nThe verbose parameter is set to false, indicating that the agent will not provide verbose or detailed output.\\n You can accomplish this by following the shell commands provided below:\\nCreating a LangSmith client\\nNext, create a LangSmith client to interact with the API:\\nIf you’re using Python, run the following commands to import the module:\\n This code also handles exceptions that may occur during the agent execution:\\nIt’s also important to call the wait_for_all_tracers function from the langchain.callbacks.tracers.langchain module as shown in the code snippet below:\\nCalling the wait_for_all_tracers function helps ensure that logs and traces are submitted in full before the program proceeds. The temperature parameter will be set to 0, implying that the generated response will be more deterministic as shown in the code snippet below:\\nNow, let’s call the load_tools function with a list of tool APIs, such as serpapi and llm-math, and also take the llm instance as a parameter. It initializes a chat model, loads specific tools, and creates an agent that can generate responses based on descriptions:\\nInput processing with exception handling\\nThe code below defines a list of input examples using the asyncio library to asynchronously run the agent on each input and gather the results for further processing.', metadata={'title': 'Using LangSmith to test LLMs and AI applications', 'source': 'https://blog.logrocket.com/langsmith-test-llms-ai-applications/', 'score': 0.96833, 'images': None}),\n",
      "                          Document(page_content=\"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: “what’s happening with my application?”\", metadata={'title': 'LangSmith', 'source': 'https://www.langchain.com/langsmith', 'score': 0.93426, 'images': None}),\n",
      "                          Document(page_content='We often use this for a couple of reasons:\\nTo assess subjective qualities that automatic evaluators struggle with, like creativity or humor\\nTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right information\\nAll the annotations made using the queue are assigned as \"feedback\" to the source runs, so you can easily filter and analyze them later.\\n This feature is available at every step of a nested chain, enabling you to add examples for an end-to-end chain, an intermediary chain (such as a LLM Chain), or simply the LLM or Chat Model.\\n The LangSmith client makes it easy to pull down a dataset and then run a chain over them, logging the results to a new project associated with the dataset. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.\\n You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.\\n', metadata={'title': 'LangSmith Overview and User Guide | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/overview', 'score': 0.93118, 'images': None}),\n",
      "                          Document(page_content=\"If you already use LangChain, you can connect to LangSmith in a few steps:\\nFor environments where process.env is not defined, initialize by explicitly passing keys:\\nIf you don't want to use LangChain in your LLM application, you can get started with LangSmith in just a few steps:\\nCongratulations! It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.\\n Quick Start\\u200b\\nIf following along with code is more your thing, we've set up a Jupyter notebook at this link to help you get started with LangSmith.\\n LangChain JS Docs for the TypeScript LangChain library\\nDiscord: Join us on our Discord to discuss all things LangChain!\\n Next Steps\\u200b\\nRead the LangSmith Overview to learn more about what LangSmith has to offer.\\n\", metadata={'title': 'LangSmith | ️ ️ LangSmith', 'source': 'https://docs.smith.langchain.com/', 'score': 0.90149, 'images': None}),\n",
      "                          Document(page_content='A deep dive into the latest product from the creators of LangChain 🦜\\n--\\n3\\nCobus Greyling\\nLangSmith\\nI was fortunate to get early access to the LangSmith platform and in this article you will find practical code examples and demonstration…\\n--\\nLists\\nNatural Language Processing\\nPredictive Modeling w/ Python\\nAI Regulation\\nPractical Guides to Machine Learning\\nYule Wang, PhD\\nA Complete Guide to LLMs-based Autonomous Agents (Part I):\\n—\\u200a—\\u200aChain of Thought, Plan and Solve/Execute, Self-Ask, ReAct, Reflexion, Self-Consistency, Tree of Thoughts and Graph of Thoughts\\n--\\n1\\nRyan Nguyen\\nin\\nBetter Programming\\nLlamaIndex: How To Evaluate Your RAG (Retrieval Augmented Generation) Applications\\nClassic 10k reports with Australian real estate market reports to demonstrate the end-to-end evaluation process\\n--\\n2\\nKelvin Lu\\nTracing How LangChain Works Behind the Scenes\\nIntroduction of LLM Tracing technique with both LangChain built-in tracing funciton and LangChain Visualizer.\\n --\\nCameron R. Wolfe, Ph.D.\\nin\\nTowards Data Science\\nChain of Thought Prompting for LLMs\\nA practical and simple approach for “reasoning” with LLMs\\n--\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams A Step-by-Step Guide to Deploying ChromaDB in the Cloud\\n--\\nBenoit Ruiz\\nin\\nBetter Programming\\nAdvice From a Software Engineer With 8 Years of Experience\\nPractical tips for those who want to advance in their careers\\n--\\n233\\nVinita\\nin\\nBetter Programming\\n4 Strategies to Give Effective Feedback to a Difficult Person\\nRespect is like air. But if you take it away, it’s all that people can think about.\\n--\\n21\\nRicardo Ledan\\nin\\nBetter Programming\\nBuilding Context-Aware Question-Answering Systems With LLMs\\nA step-by-step guide to using embeddings, vector search, and prompt engineering for building context-aware question-answering systems\\n--\\n1\\nRecommended from Medium\\nLogan Kilpatrick\\nWhat is LangSmith and why should I care as a developer?\\n Ricardo Ledan\\nFollow\\nBetter Programming\\n--\\nShare\\nWhat is LangSmith?\\n', metadata={'title': 'The Art of LangSmithing - Better Programming', 'source': 'https://betterprogramming.pub/the-art-of-langsmithing-42dcd191a220', 'score': 0.86327, 'images': None}),\n",
      "                          Document(page_content=\"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", metadata={'title': 'Peering Into the Soul of AI Decision-Making with LangSmith', 'source': 'https://blog.langchain.dev/peering-into-the-soul-of-ai-decision-making-with-langsmith/', 'score': 0.85458, 'images': None}),\n",
      "                          Document(page_content='We consistently see developers relying on LangSmith to track the system-level performance of their application (like latency and cost), track the model/chain performance (through associating feedback with runs), debug issues (diving into a particular run that went wrong), and establish a broad understanding of how users are interacting with their application and what their experience is like.\\n Over the last few months, we’ve been working directly with some early design partners and testing it on our own internal workflows, and we’ve found LangSmith helps teams in 5 core ways:\\nDebugging\\nLangSmith gives you full visibility into model inputs and output of every step in the chain of events. As a very simple example, we considered it to be table stakes for LangSmith to help users easily create datasets from existing logs and use them immediately for testing and evaluation, seamlessly connecting the logging/debugging workflows to the testing/evaluation ones.\\n A unified platform\\nWhile each of these product areas provide unique value, often at a specific point in time in the development process, we believe a great deal of the long term impact of LangSmith will come from having a single, fully-integrated hub to do this work from. Additionally, tracing and evaluating the complex agent prompt chains is much easier, reducing the time required to debug and refine our prompts, and giving us the confidence to move to deployment.”\\n', metadata={'title': 'Announcing LangSmith, a unified platform for debugging, testing ...', 'source': 'https://blog.langchain.dev/announcing-langsmith/', 'score': 0.85453, 'images': None}),\n",
      "                          Document(page_content='But what are the production challenges that need to be solved which were not as relevant in prototyping?\\nReliability — it is deceptively easy to build something that works well for a simple constrained example but actually still quite hard today to build LLM applications with the consistency that most companies would want.\\n for tools\\nKim Seon Woo - Nov 6\\nComo deixar o Swagger com tema dark mode usando NestJS\\nWiliam V. Joaquim - Nov 5\\nData visualizing\\nBIRINGANINE BASEME Destin\\n- Oct 7\\nFree Face-Swap AI 🎭 with Source Code for Web and Mobile App.\\nshadee22 - As you build more complex workflows, it can be hard to understand exactly what queries are moving through different flows so a simple UI to see this and log the historical data is going to be a value add from day one.\\n A huge part of the value add for LangSmith is being able to do all of these things from a simple and intuitive UI which significantly reduces the barrier to entry for those without a software background.\\n [Quick note: I am writing this article to reflect my personal views as I explore the LLM ecosystem and this is not intended to represent the views of my employer, hence being on my personal blog]\\nWhat is LangSmith?', metadata={'title': 'What is LangSmith and why should I care as a developer?', 'source': 'https://dev.to/logankilpatrick/what-is-langsmith-and-why-should-i-care-as-a-developer-19k', 'score': 0.85311, 'images': None}),\n",
      "                          Document(page_content='Python Examples\\u200b\\nTypeScript / JavaScript Testing Examples\\u200b\\nIncorporate LangSmith into your TS/JS testing and evaluation workflow:\\nUsing Feedback\\u200b\\nHarness user feedback, \"ai-assisted\" feedback, and other signals to improve, monitor, and personalize your applications. Feedback can be user-generated or \"automated\" using functions or even calls to an LLM:\\nExporting data for fine-tuning\\u200b\\nFine-tune an LLM on collected run data using these recipes:\\nExploratory Data Analysis\\u200b\\nTurn your trace data into actionable insights: LangSmith Cookbook\\nThe LangSmith Cookbook offers hands-on code examples to inspire and assist in your projects.\\n While our standard documentation covers the basics, this repository delves into common patterns and some real-world use-cases, empowering you to optimize your LLM applications further.\\n While we\\'ve incorporated summaries and overviews from the READMEs here, the full code resides\\nin our GitHub repository.\\n', metadata={'title': 'LangSmith Cookbook | ️ ️ LangSmith - docs.smith.langchain.com', 'source': 'https://docs.smith.langchain.com/cookbook', 'score': 0.82527, 'images': None})]}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/Docs/end_time',\n",
      "  'value': '2024-01-29T09:36:39.415+00:00'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': ''})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Lang'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Smith'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' is'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' a'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is a'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' platform'},\n",
      " {'op': 'replace', 'path': '/final_output', 'value': 'LangSmith is a platform'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' that'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' helps'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' trace'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' evaluate'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' language'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' model'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' applications'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' intelligent'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' agents'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' allowing'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' users'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' to'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' move'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' from'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' prototype'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' to'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' production'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' It'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' provides'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' tools'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' for'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' loading'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' specific'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' language'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' models'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' initializing'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' agents'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' creating'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' a'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Lang'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Smith'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' client'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' handling'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' exceptions'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' processing'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' input'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Lang'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Smith'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' also'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' allows'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' users'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' to'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' debug'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' test'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' evaluate'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' monitor'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' chains'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' and'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' intelligent'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' agents'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' built'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' on'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' any'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' L'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any L'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'LM'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' ('},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM ('})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Language'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Model'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ')'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model)'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' framework'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' It'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' seamlessly'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' integrates'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' with'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' Lang'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with Lang'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'Chain'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ','},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain,'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' an'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' open'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '-source'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an '\n",
      "           'open-source'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' framework'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' for'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' building'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' with'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building with'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ' L'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building with L'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 'LM'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building with LLM'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': 's'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building with LLMs'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': '.'},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': 'LangSmith is a platform that helps trace and evaluate language '\n",
      "           'model applications and intelligent agents, allowing users to move '\n",
      "           'from prototype to production. It provides tools for loading '\n",
      "           'specific language models, initializing agents, creating a '\n",
      "           'LangSmith client, handling exceptions, and processing input. '\n",
      "           'LangSmith also allows users to debug, test, evaluate, and monitor '\n",
      "           'chains and intelligent agents built on any LLM (Language Model) '\n",
      "           'framework. It seamlessly integrates with LangChain, an open-source '\n",
      "           'framework for building with LLMs.'})RunLogPatch({'op': 'add', 'path': '/streamed_output/-', 'value': ''})"
     ]
    }
   ],
   "source": [
    "async for s in retrieval_chain.astream_log({\"question\": \"what is langsmith\"}, include_names=[\"Docs\"]):\n",
    "    print(s, end=\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:36:42.442575300Z",
     "start_time": "2024-01-29T09:36:37.848722800Z"
    }
   },
   "id": "429195a68978c8d4",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agents\n",
    "# Stream Actions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4894eab1931be7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()\n",
    "tools = [search]\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "# If you want to see the prompt in full, you can at: https://smith.langchain.com/hub/hwchase17/openai-functions-agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:41:46.907859300Z",
     "start_time": "2024-01-29T09:41:39.610074900Z"
    }
   },
   "id": "dd96258a5d268ab",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actions': [AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})])], 'messages': [AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]}\n",
      "------\n",
      "{'steps': [AgentStep(action=AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]), observation=[{'url': 'https://www.weather2travel.com/california/san-francisco/january/', 'content': 'San Francisco weather in January 2024 Expect 13°C daytime maximum temperatures  long-term weather averages for San Francisco in January before you book your next holiday to California in 2024/2025.  San Francisco January sunrise & sunset times  Daytime temperatures usually reach 13°C in San Francisco in January, falling to 7°C at night.San Francisco weather in January 2024 Expect 13°C daytime maximum temperatures in the shade with on average 6 hours of sunshine per day in San Francisco in January. Check more long-term weather averages for San Francisco in January before you book your next holiday to California in 2024/2025. 13 13°C max day temperature 6'}, {'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/', 'content': 'San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July'}, {'url': 'https://www.metoffice.gov.uk/weather/forecast/9q8yym8kr', 'content': 'Thu 11 Jan Thu 11 Jan Seven day forecast for San Francisco  San Francisco (United States of America) weather Find a forecast  Sat 6 Jan Sat 6 Jan Sun 7 Jan Sun 7 Jan Mon 8 Jan Mon 8 Jan Tue 9 Jan Tue 9 Jan Wed 10 Jan Wed 10 Jan Thu 11 Jan  Find a forecast Please choose your location from the nearest places to : Forecast days Today Today Sat 6 Jan Sat 6 JanSan Francisco 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... Eight day forecast for San Francisco. Cloudy. Sunrise: 07:18. Sunset: ... (29 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00'}])], 'messages': [FunctionMessage(content='[{\"url\": \"https://www.weather2travel.com/california/san-francisco/january/\", \"content\": \"San Francisco weather in January 2024 Expect 13°C daytime maximum temperatures  long-term weather averages for San Francisco in January before you book your next holiday to California in 2024/2025.  San Francisco January sunrise & sunset times  Daytime temperatures usually reach 13°C in San Francisco in January, falling to 7°C at night.San Francisco weather in January 2024 Expect 13°C daytime maximum temperatures in the shade with on average 6 hours of sunshine per day in San Francisco in January. Check more long-term weather averages for San Francisco in January before you book your next holiday to California in 2024/2025. 13 13°C max day temperature 6\"}, {\"url\": \"https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/\", \"content\": \"San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July\"}, {\"url\": \"https://www.metoffice.gov.uk/weather/forecast/9q8yym8kr\", \"content\": \"Thu 11 Jan Thu 11 Jan Seven day forecast for San Francisco  San Francisco (United States of America) weather Find a forecast  Sat 6 Jan Sat 6 Jan Sun 7 Jan Sun 7 Jan Mon 8 Jan Mon 8 Jan Tue 9 Jan Tue 9 Jan Wed 10 Jan Wed 10 Jan Thu 11 Jan  Find a forecast Please choose your location from the nearest places to : Forecast days Today Today Sat 6 Jan Sat 6 JanSan Francisco 7 day weather forecast including weather warnings, temperature, rain, wind, visibility, humidity and UV ... Eight day forecast for San Francisco. Cloudy. Sunrise: 07:18. Sunset: ... (29 January 2024) Time 00:00 01:00 02:00 03:00 04:00 05:00 06:00 07:00 08:00 09:00 10:00 11:00 12:00 13:00\"}]', name='tavily_search_results_json')]}\n",
      "------\n",
      "{'actions': [AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in Los Angeles'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in Los Angeles'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in Los Angeles\"\\n}', 'name': 'tavily_search_results_json'}})])], 'messages': [AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in Los Angeles\"\\n}', 'name': 'tavily_search_results_json'}})]}\n",
      "------\n",
      "{'steps': [AgentStep(action=AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in Los Angeles'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in Los Angeles'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in Los Angeles\"\\n}', 'name': 'tavily_search_results_json'}})]), observation=[{'url': 'https://weatherspark.com/h/m/1705/2024/1/Historical-Weather-in-January-2024-in-Los-Angeles-California-United-States', 'content': 'January 2024 Weather History in Los Angeles California, United States  Daily Precipitation in January 2024 in Los Angeles Observed Weather in January 2024 in Los Angeles  Los Angeles Temperature History January 2024 Hourly Temperature in January 2024 in Los Angeles  Hours of Daylight and Twilight in January 2024 in Los AngelesThe daily range of reported temperatures (gray bars) and 24-hour highs (red ticks) and lows (blue ticks), placed over the daily average high (faint red line) and low (faint blue line) temperature, with 25th to 75th and 10th to 90th percentile bands. Hourly Temperature in January 2024 in Los Angeles'}, {'url': 'https://www.whereandwhen.net/when/north-america/california/los-angeles-ca/january/', 'content': 'Best time to go to Los Angeles? Weather in Los Angeles in january 2024  How was the weather last january? Here is the day by day recorded weather in Los Angeles in january 2023:  Weather data for Los Angeles for january are derived from an average of the weather forecast since 2009 in Los Angeles.  Seasonal average climate and temperature of Los Angeles in januaryWeather in Los Angeles in january 2024. The weather in Los Angeles (California) in january comes from statistical datas on the last years. You can view the weather statistics for the whole month, but also navigating through the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 52°F to 56°F. 30-01-2023 50°F to 58°F ...'}, {'url': 'https://www.inkl.com/news/normal-weather-expected-in-los-angeles-today-29-january-2024', 'content': 'Normal Weather Expected in Los Angeles Today - 29 January 2024  wake up on the delightful morning of 29 January 2024, they can expect to be blessed with pleasantly normal weather.  Title: A Blissfully Pleasant Day in the City of Angels: Normal Weather Expected in Los Angeles Today  under the warm sun and cool sea breeze that Los Angeles has graciously bestowed upon us today.As residents of Los Angeles wake up on the delightful morning of 29 January 2024, they can expect to be blessed with pleasantly normal weather. With temperatures reaching a maximum of 23°C (74°F) and a minimum of 15°C (59°F), it promises to be a day where comfort and enjoyment can be found in every corner of this vibrant city.'}, {'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/los-angeles-714829/t/january-1/', 'content': 'Los Angeles Weather in January  you can find all information about the weather in Los Angeles in January:  Los Angeles weather in January Los Angeles weather by month // weather averages 11.9 (53.5) 6.7 (44.1) 19.5 (67.2) 84  Data: 1999 - 2019: avg. Sun hours Los Angeles weather and climate for further monthsLos Angeles Weather in January Are you planning a holiday with hopefully nice weather in Los Angeles in January 2024? Here you can find all information about the weather in Los Angeles in January: ... 29. January: 12 °C | 54 °F : 20 °C | 68 °F: 7 °C | 44 °F: 1.9 mm | 0.1 inch. 30. January'}])], 'messages': [FunctionMessage(content='[{\"url\": \"https://weatherspark.com/h/m/1705/2024/1/Historical-Weather-in-January-2024-in-Los-Angeles-California-United-States\", \"content\": \"January 2024 Weather History in Los Angeles California, United States  Daily Precipitation in January 2024 in Los Angeles Observed Weather in January 2024 in Los Angeles  Los Angeles Temperature History January 2024 Hourly Temperature in January 2024 in Los Angeles  Hours of Daylight and Twilight in January 2024 in Los AngelesThe daily range of reported temperatures (gray bars) and 24-hour highs (red ticks) and lows (blue ticks), placed over the daily average high (faint red line) and low (faint blue line) temperature, with 25th to 75th and 10th to 90th percentile bands. Hourly Temperature in January 2024 in Los Angeles\"}, {\"url\": \"https://www.whereandwhen.net/when/north-america/california/los-angeles-ca/january/\", \"content\": \"Best time to go to Los Angeles? Weather in Los Angeles in january 2024  How was the weather last january? Here is the day by day recorded weather in Los Angeles in january 2023:  Weather data for Los Angeles for january are derived from an average of the weather forecast since 2009 in Los Angeles.  Seasonal average climate and temperature of Los Angeles in januaryWeather in Los Angeles in january 2024. The weather in Los Angeles (California) in january comes from statistical datas on the last years. You can view the weather statistics for the whole month, but also navigating through the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 52°F to 56°F. 30-01-2023 50°F to 58°F ...\"}, {\"url\": \"https://www.inkl.com/news/normal-weather-expected-in-los-angeles-today-29-january-2024\", \"content\": \"Normal Weather Expected in Los Angeles Today - 29 January 2024  wake up on the delightful morning of 29 January 2024, they can expect to be blessed with pleasantly normal weather.  Title: A Blissfully Pleasant Day in the City of Angels: Normal Weather Expected in Los Angeles Today  under the warm sun and cool sea breeze that Los Angeles has graciously bestowed upon us today.As residents of Los Angeles wake up on the delightful morning of 29 January 2024, they can expect to be blessed with pleasantly normal weather. With temperatures reaching a maximum of 23°C (74°F) and a minimum of 15°C (59°F), it promises to be a day where comfort and enjoyment can be found in every corner of this vibrant city.\"}, {\"url\": \"https://en.climate-data.org/north-america/united-states-of-america/california/los-angeles-714829/t/january-1/\", \"content\": \"Los Angeles Weather in January  you can find all information about the weather in Los Angeles in January:  Los Angeles weather in January Los Angeles weather by month // weather averages 11.9 (53.5) 6.7 (44.1) 19.5 (67.2) 84  Data: 1999 - 2019: avg. Sun hours Los Angeles weather and climate for further monthsLos Angeles Weather in January Are you planning a holiday with hopefully nice weather in Los Angeles in January 2024? Here you can find all information about the weather in Los Angeles in January: ... 29. January: 12 °C | 54 °F : 20 °C | 68 °F: 7 °C | 44 °F: 1.9 mm | 0.1 inch. 30. January\"}]', name='tavily_search_results_json')]}\n",
      "------\n",
      "{'output': 'The weather in San Francisco in January is expected to have a daytime maximum temperature of around 13°C (55°F) with an average of 6 hours of sunshine per day. The temperature at night can drop to around 7°C (45°F). You can find more detailed information about the weather in San Francisco in January [here](https://www.weather2travel.com/california/san-francisco/january/).\\n\\nAs for Los Angeles, on January 29, 2024, the weather is expected to be pleasantly normal with a maximum temperature of 23°C (74°F) and a minimum temperature of 15°C (59°F). You can find more information about the weather in Los Angeles in January [here](https://www.inkl.com/news/normal-weather-expected-in-los-angeles-today-29-january-2024).', 'messages': [AIMessage(content='The weather in San Francisco in January is expected to have a daytime maximum temperature of around 13°C (55°F) with an average of 6 hours of sunshine per day. The temperature at night can drop to around 7°C (45°F). You can find more detailed information about the weather in San Francisco in January [here](https://www.weather2travel.com/california/san-francisco/january/).\\n\\nAs for Los Angeles, on January 29, 2024, the weather is expected to be pleasantly normal with a maximum temperature of 23°C (74°F) and a minimum temperature of 15°C (59°F). You can find more information about the weather in Los Angeles in January [here](https://www.inkl.com/news/normal-weather-expected-in-los-angeles-today-29-january-2024).')]}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"input\": \"what is the weather in SF and then LA\"}):\n",
    "    print(chunk)\n",
    "    print(\"------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:49:37.660148700Z",
     "start_time": "2024-01-29T09:49:17.220909800Z"
    }
   },
   "id": "d0406b3865b6b361",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stream Tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a55bb84be3b54bf3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, streaming=True)\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:52:16.970402100Z",
     "start_time": "2024-01-29T09:52:15.874682700Z"
    }
   },
   "id": "75e465679cb86e0e",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunLogPatch({'op': 'replace',\n",
      "  'path': '',\n",
      "  'value': {'final_output': None,\n",
      "            'id': '33d03f5d-bf44-4e12-b3e5-61b0b99b3ef3',\n",
      "            'logs': {},\n",
      "            'name': 'AgentExecutor',\n",
      "            'streamed_output': [],\n",
      "            'type': 'chain'}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '4e06fbc3-bee4-49f8-a88f-f26411827538',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'start_time': '2024-01-29T09:52:29.203+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:3'],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '', 'name': 'tavily_search_results_json'}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' ', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' \"', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': 'query', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '\":', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' \"', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': 'weather', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' in', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' San', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': ' Francisco', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '\"\\n', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '}', 'name': ''}})})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/final_output',\n",
      "  'value': {'generations': [[{'generation_info': {'finish_reason': 'function_call'},\n",
      "                              'message': AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}}),\n",
      "                              'text': '',\n",
      "                              'type': 'ChatGenerationChunk'}]],\n",
      "            'llm_output': None,\n",
      "            'run': None}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI/end_time',\n",
      "  'value': '2024-01-29T09:52:30.735+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': {'actions': [AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})])],\n",
      "            'messages': [AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]}},\n",
      " {'op': 'replace',\n",
      "  'path': '/final_output',\n",
      "  'value': {'actions': [AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})])],\n",
      "            'messages': [AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]}})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': {'messages': [FunctionMessage(content='[{\"url\": \"https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/\", \"content\": \"Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in january  Seasonal average climate and temperature of San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 47°F to 52°F. 30-01-2023 40°F to 56°F. 31-01-2023 41°F to ...\"}, {\"url\": \"https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/\", \"content\": \"San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July\"}]', name='tavily_search_results_json')],\n",
      "            'steps': [AgentStep(action=AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]), observation=[{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/', 'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in january  Seasonal average climate and temperature of San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 47°F to 52°F. 30-01-2023 40°F to 56°F. 31-01-2023 41°F to ...'}, {'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/', 'content': 'San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July'}])]}},\n",
      " {'op': 'add',\n",
      "  'path': '/final_output/steps',\n",
      "  'value': [AgentStep(action=AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"weather in San Francisco\"\\n}', 'name': 'tavily_search_results_json'}})]), observation=[{'url': 'https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/', 'content': 'Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in january  Seasonal average climate and temperature of San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 47°F to 52°F. 30-01-2023 40°F to 56°F. 31-01-2023 41°F to ...'}, {'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/', 'content': 'San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July'}])]},\n",
      " {'op': 'add',\n",
      "  'path': '/final_output/messages/1',\n",
      "  'value': FunctionMessage(content='[{\"url\": \"https://www.whereandwhen.net/when/north-america/california/san-francisco-ca/january/\", \"content\": \"Best time to go to San Francisco? Weather in San Francisco in january 2024  How was the weather last january? Here is the day by day recorded weather in San Francisco in january 2023:  8% 46% 29% 12% 8% Evolution of daily average temperature and precipitation in San Francisco in january  Seasonal average climate and temperature of San Francisco in januaryWeather in San Francisco in january 2024. The weather in San Francisco in january comes from statistical datas on the past years. You can view the weather statistics the entire month, but also by using the tabs for the beginning, the middle and the end of the month. ... 29-01-2023 47°F to 52°F. 30-01-2023 40°F to 56°F. 31-01-2023 41°F to ...\"}, {\"url\": \"https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/\", \"content\": \"San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July\"}]', name='tavily_search_results_json')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2',\n",
      "  'value': {'end_time': None,\n",
      "            'final_output': None,\n",
      "            'id': '7f64d1b0-ef34-4233-b18c-ff8c29beaaf3',\n",
      "            'metadata': {},\n",
      "            'name': 'ChatOpenAI',\n",
      "            'start_time': '2024-01-29T09:52:35.661+00:00',\n",
      "            'streamed_output': [],\n",
      "            'streamed_output_str': [],\n",
      "            'tags': ['seq:step:3'],\n",
      "            'type': 'llm'}})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI:2/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': 'The'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='The')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' weather'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' weather')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' in'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' in')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' San'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' San')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' Francisco'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' Francisco')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' can'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' can')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' vary'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' vary')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' depending'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' depending')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' on'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' on')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' time'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' time')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' of'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' of')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' year'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' year')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' In'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' In')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' January'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' January')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ','},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=',')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' average'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' average')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' temperature'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' temperature')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' ranges'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' ranges')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' from'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' from')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' '},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' ')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '40'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='40')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '°F'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='°F')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' '},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' ')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '56'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='56')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '°F'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='°F')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' It'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' It')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' is'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' is')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' recommended'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' recommended')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' to')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' check'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' check')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' weather'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' weather')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' forecast'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' forecast')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' for'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' for')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' the'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' the')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' most'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' most')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' accurate'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' accurate')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' and'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' and')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' up'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' up')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '-to'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-to')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '-date'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='-date')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': ' information'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content=' information')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output_str/-',\n",
      "  'value': '.'},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='.')})\n",
      "RunLogPatch({'op': 'add', 'path': '/logs/ChatOpenAI:2/streamed_output_str/-', 'value': ''},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/streamed_output/-',\n",
      "  'value': AIMessageChunk(content='')})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/final_output',\n",
      "  'value': {'generations': [[{'generation_info': {'finish_reason': 'stop'},\n",
      "                              'message': AIMessageChunk(content='The weather in San Francisco can vary depending on the time of year. In January, the average temperature ranges from 40°F to 56°F. It is recommended to check the weather forecast for the most accurate and up-to-date information.'),\n",
      "                              'text': 'The weather in San Francisco can vary '\n",
      "                                      'depending on the time of year. In '\n",
      "                                      'January, the average temperature ranges '\n",
      "                                      'from 40°F to 56°F. It is recommended to '\n",
      "                                      'check the weather forecast for the most '\n",
      "                                      'accurate and up-to-date information.',\n",
      "                              'type': 'ChatGenerationChunk'}]],\n",
      "            'llm_output': None,\n",
      "            'run': None}},\n",
      " {'op': 'add',\n",
      "  'path': '/logs/ChatOpenAI:2/end_time',\n",
      "  'value': '2024-01-29T09:52:37.201+00:00'})\n",
      "RunLogPatch({'op': 'add',\n",
      "  'path': '/streamed_output/-',\n",
      "  'value': {'messages': [AIMessage(content='The weather in San Francisco can vary depending on the time of year. In January, the average temperature ranges from 40°F to 56°F. It is recommended to check the weather forecast for the most accurate and up-to-date information.')],\n",
      "            'output': 'The weather in San Francisco can vary depending on the '\n",
      "                      'time of year. In January, the average temperature '\n",
      "                      'ranges from 40°F to 56°F. It is recommended to check '\n",
      "                      'the weather forecast for the most accurate and '\n",
      "                      'up-to-date information.'}},\n",
      " {'op': 'add',\n",
      "  'path': '/final_output/output',\n",
      "  'value': 'The weather in San Francisco can vary depending on the time of '\n",
      "           'year. In January, the average temperature ranges from 40°F to '\n",
      "           '56°F. It is recommended to check the weather forecast for the most '\n",
      "           'accurate and up-to-date information.'},\n",
      " {'op': 'add',\n",
      "  'path': '/final_output/messages/2',\n",
      "  'value': AIMessage(content='The weather in San Francisco can vary depending on the time of year. In January, the average temperature ranges from 40°F to 56°F. It is recommended to check the weather forecast for the most accurate and up-to-date information.')})\n"
     ]
    }
   ],
   "source": [
    "async for chunk in agent_executor.astream_log(\n",
    "    {\"input\": \"what is the weather in sf\", \"chat_history\": []},\n",
    "    include_names=[\"ChatOpenAI\"],\n",
    "):\n",
    "    print(chunk)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:52:37.220618800Z",
     "start_time": "2024-01-29T09:52:29.187757500Z"
    }
   },
   "id": "2fd1f280a5680d0b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56eedd036e47e631"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
